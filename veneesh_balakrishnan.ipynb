{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkfgAMMlNhF3"
   },
   "source": [
    "# Identifying Entities in Healthcare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhNx-aaONooj"
   },
   "source": [
    "## <font color=\"blue\"> Introduction:\n",
    "\n",
    "A health tech company called BeHealthy has a web platform that allows doctors to list their services and manage patient interactions and provides services for patients such as booking interactions with doctors and ordering medicines online. Here, doctors can easily organise appointments, track past medical records and provide e-prescriptions, thus generating huge amount of data day by day and through which we can take proper decisions using machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIPz1rOyPsxi"
   },
   "source": [
    "## <font color=\"blue\"> Problem statement:\n",
    "\n",
    "In the generated text, there is lot of diseases and their respective treatment are explicitly mentioned. In order to map the disease with their treatment, we can build an algorithm using syntactic processing in NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJKDgUvHRNuj"
   },
   "source": [
    "## <font color=\"blue\"> Importing and installing usefull packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LMBUg0u8NZf_"
   },
   "outputs": [],
   "source": [
    "#!pip install pycrf\n",
    "#!pip install sklearn-crfsuite\n",
    "\n",
    "import spacy\n",
    "import sklearn\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "model = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gn8sgoYPSiv_"
   },
   "source": [
    "## <font color=\"blue\"> Data preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuqSy4mCSqxR"
   },
   "source": [
    "The dataset provided is in the form of one word per line. Let's understand the format of data below:\n",
    "- Suppose there are *x* words in a sentence, then there will be *x* continuous lines with one word in each line. \n",
    "- Further, the two sentences are separated by empty lines. The labels for the data follow the same format.\n",
    "\n",
    "We need to pre-process the data to recover the complete sentences and their labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Rm9ztVRTmak"
   },
   "source": [
    "**Constructing the proper sentences from individual words and printing the first 5 sentences.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZFB28ApLSf7v"
   },
   "outputs": [],
   "source": [
    "# Creating a function for converting words into sentences\n",
    "\n",
    "def words_to_sentence(path):\n",
    "  # opening the file \n",
    "  file = open(path, \"r\")\n",
    "\n",
    "  # reading the lines and storing in a variable\n",
    "  file_name = file.readlines()\n",
    "  file.close()\n",
    "\n",
    "  # Creating a output list to store the all the sentences\n",
    "  output_list = []\n",
    "\n",
    "  # creating a string to store each sentences to append separately in the output list\n",
    "  sentence = \"\"\n",
    "\n",
    "  # iterating through all the words and storing in the output list\n",
    "  for word in file_name:\n",
    "    word = word.strip(\"\\n\")\n",
    "    if word != \"\":\n",
    "      if sentence:\n",
    "        sentence +=\" \"+word\n",
    "      else:\n",
    "        sentence = word\n",
    "\n",
    "    else:\n",
    "      output_list.append(sentence)\n",
    "      sentence = \"\"\n",
    "\n",
    "  return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wsICkOo0XsHD"
   },
   "outputs": [],
   "source": [
    "# Creating the sentences and labels for train and test dataset\n",
    "train_sentences = words_to_sentence(\"train_sent\")\n",
    "train_labels = words_to_sentence(\"train_label\")\n",
    "test_sentences = words_to_sentence(\"test_sent\")\n",
    "test_labels = words_to_sentence(\"test_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j-ODQG1kbDLr",
    "outputId": "e6976e6b-e4de-48a8-d3b5-9c939530b60d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Row 1 \u001b[0m\n",
      "Sentence is:  All live births > or = 23 weeks at the University of Vermont in 1995 ( n = 2395 ) were retrospectively analyzed for delivery route , indication for cesarean , gestational age , parity , and practice group ( to reflect risk status )\n",
      "Labels for sentence is: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001b[1m Row 2 \u001b[0m\n",
      "Sentence is:  The total cesarean rate was 14.4 % ( 344 of 2395 ) , and the primary rate was 11.4 % ( 244 of 2144 )\n",
      "Labels for sentence is: O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001b[1m Row 3 \u001b[0m\n",
      "Sentence is:  Abnormal presentation was the most common indication ( 25.6 % , 88 of 344 )\n",
      "Labels for sentence is: O O O O O O O O O O O O O O O\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001b[1m Row 4 \u001b[0m\n",
      "Sentence is:  The `` corrected '' cesarean rate ( maternal-fetal medicine and transported patients excluded ) was 12.4 % ( 273 of 2194 ) , and the `` corrected '' primary rate was 9.6 % ( 190 of 1975 )\n",
      "Labels for sentence is: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001b[1m Row 5 \u001b[0m\n",
      "Sentence is:  Arrest of dilation was the most common indication in both `` corrected '' subgroups ( 23.4 and 24.6 % , respectively )\n",
      "Labels for sentence is: O O O O O O O O O O O O O O O O O O O O O O\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# printing first five sentences and its labels\n",
    "for i in range(5):\n",
    "  print(\"\\033[1m\",f\"Row {i+1}\",\"\\033[0m\")\n",
    "  print(f\"Sentence is: \", train_sentences[i])\n",
    "  print(f\"Labels for sentence is:\", train_labels[i])\n",
    "  print(\"--\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4C41x7GazBY"
   },
   "source": [
    "**Counting the number of sentences in the processed train and test dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wVxcnGrba1P7",
    "outputId": "1b033f2e-fe77-4b58-946b-6a520f6505c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in processed train dataset is: 2599\n",
      "Number of sentences in processed test dataset is: 1056\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of sentences in processed train dataset is: {len(train_sentences)}\")\n",
    "print(f\"Number of sentences in processed test dataset is: {len(test_sentences)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g30SNDC5e3s0"
   },
   "source": [
    "**Counting the number of lines of labels in the processed train and test dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "urC3yP8oeOYm",
    "outputId": "c84ce812-20c7-4ace-c719-9636e5db168d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines of labels in processed train dataset is: 2599\n",
      "Number of lines of labels in processed test dataset is: 1056\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of lines of labels in processed train dataset is: {len(train_labels)}\")\n",
    "print(f\"Number of lines of labels in processed test dataset is: {len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUSoXPaYfQYY"
   },
   "source": [
    "## <font color=\"blue\"> Concept Identification:\n",
    "\n",
    "We will first explore what are the various concepts present in the dataset. For this, we will use PoS Tagging. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hPkTpYg3fsv"
   },
   "source": [
    "**Extracting those tokens which have NOUN or PROPN as their PoS tag and find their frequency.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LmV0GCqXe-ff"
   },
   "outputs": [],
   "source": [
    "# Identifying the noun and pronouns in the train and test sentences\n",
    "\n",
    "# Creating a variable to store the noun and propn in the corpus\n",
    "noun_pronoun_list = []\n",
    "\n",
    "# Creating the list of train and test sentences\n",
    "corpus = [train_sentences, test_sentences]\n",
    "\n",
    "# Extracting the noun and propn from the corpus and storing into noun_pronoun_list\n",
    "for sentences in corpus:\n",
    "  for sentence in sentences:\n",
    "    nlp = model(sentence)\n",
    "    for token in nlp:\n",
    "      if token.pos_ == \"NOUN\" or token.pos_ == \"PROPN\":\n",
    "        noun_pronoun_list.append(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BcdKHBMb0LPt"
   },
   "outputs": [],
   "source": [
    "# Creating a series from the created list\n",
    "df_noun_pronoun = pd.Series(noun_pronoun_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eIdMyu0E3sqV"
   },
   "source": [
    "**Printing the top 25 most common tokens with NOUN or PROPN PoS tags.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fEcRLc2W0LMn",
    "outputId": "d9373c1e-29f7-47e6-b7a9-75e14da55361"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patients        492\n",
       "treatment       281\n",
       "%               247\n",
       "cancer          200\n",
       "therapy         175\n",
       "study           152\n",
       "disease         141\n",
       "cell            140\n",
       "lung            116\n",
       "group            94\n",
       "chemotherapy     88\n",
       "gene             87\n",
       "effects          85\n",
       "results          78\n",
       "women            77\n",
       "use              74\n",
       "risk             71\n",
       "surgery          71\n",
       "cases            71\n",
       "analysis         70\n",
       "rate             67\n",
       "response         66\n",
       "survival         65\n",
       "children         64\n",
       "effect           63\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the top most Frequent nouns or proper noun in the corpus\n",
    "df_noun_pronoun.value_counts().head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-LVDJxO4C48"
   },
   "source": [
    "## <font color=\"blue\"> Defining the features for CRF:\n",
    "\n",
    "> **Performing following steps:**\n",
    "> - Defining the features with the pos tag as one of the features.\n",
    "> - Also need to consider the preceding word details of the current word for better accurate and exhaustive model.\n",
    "> - Marking the beginning and the end words of a sentence correctly in the form of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGXWO3r_6snL"
   },
   "source": [
    "**Defining the features to get the feature value for one word.**\n",
    "\n",
    "\n",
    "Defining the following features for CRF model building:\n",
    "\n",
    "- f1 = input word is in lower case; \n",
    "- f2 = last 3 characters of word;\n",
    "- f3 = last 2 characers of word;\n",
    "- f4 = 1; if the word is in uppercase, 0 otherwise;\n",
    "- f5 = 1; if word is a number; otherwise, 0 \n",
    "- f6 = 1; if the word starts with a capital letter; otherwise, 0\n",
    "- f7 = BEG, if the word is the beggining word in the sentence\n",
    "- f8 = END, if the word is the end word in the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "c0-KWAeP0LKq"
   },
   "outputs": [],
   "source": [
    "# Extracting the features from the word\n",
    "def getFeaturesForOneWord(sentence, position, pos_tag):\n",
    "  word = sentence[position]\n",
    "\n",
    "  # Defining the features using the word\n",
    "  features = [\"word.lower=\" + word.lower(),\n",
    "              \"word[-3:]=\" + word[-3:],\n",
    "              \"word[-2:]=\" + word[-2:],\n",
    "              \"word.isupper=%s\" %word.isupper(),\n",
    "              \"word.isdigit=%s\" %word.isdigit(),\n",
    "              \"word.startWithCapital=%s\" %word[0].isupper(),\n",
    "              \"word.pos=\" + pos_tag[position]]\n",
    "\n",
    "  # Defining the features using the preceding word\n",
    "  if (position > 0):\n",
    "    prev_word = sentence[position-1]\n",
    "    features.extend([\"prev_word.lower=\" + prev_word.lower(),\n",
    "                     \"prev_word.isupper=%s\" %word.isupper(),\n",
    "                     \"prev_word.isdigit=%s\" %word.isdigit(),\n",
    "                     \"prev_word.startsWithCapital=%s\" %word[0].isupper(),\n",
    "                    \"prev_word.pos=\" + pos_tag[position-1]\n",
    "                    ])\n",
    "    \n",
    "  else:\n",
    "    # Feature to track whether the word is in the beginning of the sentence\n",
    "    features.append(\"BEG\")\n",
    "\n",
    "  if(position == len(sentence) - 1):\n",
    "    features.append(\"END\")\n",
    "\n",
    "  return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zj8JYesM_4ai"
   },
   "source": [
    "## <font color=\"blue\"> Getting the features and the labels of sentences::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j61ZcYvkBCBV"
   },
   "source": [
    "**Writing a code/function to get the features for a sentence.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Vl0lQZA24klk"
   },
   "outputs": [],
   "source": [
    "# Defining a function to get features for a sentence\n",
    "def getFeaturesForOneSentence(sentence):\n",
    "\n",
    "  # Splitting the sentence into tokens\n",
    "  sentence_list = sentence.split()\n",
    "\n",
    "  # Extracting the list of pos_tag for the sentence\n",
    "  pos_tag = []\n",
    "  processed_sentence = model(sentence)\n",
    "  for token in processed_sentence:\n",
    "    pos_tag.append(token.pos_)\n",
    "\n",
    "  return [getFeaturesForOneWord(sentence_list, pos, pos_tag) for pos in range(len(sentence_list))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpmCYqp0BMjE"
   },
   "source": [
    "**Writing a code/function to get the labels of a sentence.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0tJYzqXM4kgk"
   },
   "outputs": [],
   "source": [
    "# Defining the function to get labels of a sentence\n",
    "def getLabelsInListForOneSentence(labels):\n",
    "  return labels.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwJ_SmltCD2k"
   },
   "source": [
    "**Checking the features for sample sentence.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9nzuSFH4CKMA",
    "outputId": "fc30089a-8e51-4500-ad8c-c83d98f96488"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence is **Abnormal presentation was the most common indication ( 25.6 % , 88 of 344 ) **\n",
      "\u001b[1m Word =  Abnormal \u001b[0m\n",
      "['word.lower=abnormal', 'word[-3:]=mal', 'word[-2:]=al', 'word.isupper=False', 'word.isdigit=False', 'word.startWithCapital=True', 'word.pos=ADJ', 'BEG']\n",
      "\u001b[1m Word =  presentation \u001b[0m\n",
      "['word.lower=presentation', 'word[-3:]=ion', 'word[-2:]=on', 'word.isupper=False', 'word.isdigit=False', 'word.startWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=abnormal', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADJ']\n",
      "\u001b[1m Word =  was \u001b[0m\n",
      "['word.lower=was', 'word[-3:]=was', 'word[-2:]=as', 'word.isupper=False', 'word.isdigit=False', 'word.startWithCapital=False', 'word.pos=AUX', 'prev_word.lower=presentation', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN']\n",
      "\u001b[1m Word =  the \u001b[0m\n",
      "['word.lower=the', 'word[-3:]=the', 'word[-2:]=he', 'word.isupper=False', 'word.isdigit=False', 'word.startWithCapital=False', 'word.pos=DET', 'prev_word.lower=was', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=AUX']\n",
      "\u001b[1m Word =  most \u001b[0m\n",
      "['word.lower=most', 'word[-3:]=ost', 'word[-2:]=st', 'word.isupper=False', 'word.isdigit=False', 'word.startWithCapital=False', 'word.pos=ADV', 'prev_word.lower=the', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=DET']\n",
      "\u001b[1m Word =  common \u001b[0m\n",
      "['word.lower=common', 'word[-3:]=mon', 'word[-2:]=on', 'word.isupper=False', 'word.isdigit=False', 'word.startWithCapital=False', 'word.pos=ADJ', 'prev_word.lower=most', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADV']\n",
      "\u001b[1m Word =  indication \u001b[0m\n",
      "['word.lower=indication', 'word[-3:]=ion', 'word[-2:]=on', 'word.isupper=False', 'word.isdigit=False', 'word.startWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=common', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADJ']\n",
      "\u001b[1m Word =  ( \u001b[0m\n",
      "['word.lower=(', 'word[-3:]=(', 'word[-2:]=(', 'word.isupper=False', 'word.isdigit=False', 'word.startWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=indication', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN']\n",
      "\u001b[1m Word =  25.6 \u001b[0m\n",
      "['word.lower=25.6', 'word[-3:]=5.6', 'word[-2:]=.6', 'word.isupper=False', 'word.isdigit=False', 'word.startWithCapital=False', 'word.pos=NUM', 'prev_word.lower=(', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=PUNCT']\n",
      "\u001b[1m Word =  % \u001b[0m\n",
      "['word.lower=%', 'word[-3:]=%', 'word[-2:]=%', 'word.isupper=False', 'word.isdigit=False', 'word.startWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=25.6', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NUM']\n",
      "\u001b[1m Word =  , \u001b[0m\n",
      "['word.lower=,', 'word[-3:]=,', 'word[-2:]=,', 'word.isupper=False', 'word.isdigit=False', 'word.startWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=%', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN']\n",
      "\u001b[1m Word =  88 \u001b[0m\n",
      "['word.lower=88', 'word[-3:]=88', 'word[-2:]=88', 'word.isupper=False', 'word.isdigit=True', 'word.startWithCapital=False', 'word.pos=NUM', 'prev_word.lower=,', 'prev_word.isupper=False', 'prev_word.isdigit=True', 'prev_word.startsWithCapital=False', 'prev_word.pos=PUNCT']\n",
      "\u001b[1m Word =  of \u001b[0m\n",
      "['word.lower=of', 'word[-3:]=of', 'word[-2:]=of', 'word.isupper=False', 'word.isdigit=False', 'word.startWithCapital=False', 'word.pos=ADP', 'prev_word.lower=88', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NUM']\n",
      "\u001b[1m Word =  344 \u001b[0m\n",
      "['word.lower=344', 'word[-3:]=344', 'word[-2:]=44', 'word.isupper=False', 'word.isdigit=True', 'word.startWithCapital=False', 'word.pos=NUM', 'prev_word.lower=of', 'prev_word.isupper=False', 'prev_word.isdigit=True', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADP']\n",
      "\u001b[1m Word =  ) \u001b[0m\n",
      "['word.lower=)', 'word[-3:]=)', 'word[-2:]=)', 'word.isupper=False', 'word.isdigit=False', 'word.startWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=344', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NUM', 'END']\n"
     ]
    }
   ],
   "source": [
    "# Checking the features for sample sentence\n",
    "sample_sentence = train_sentences[2]\n",
    "print(\"The sentence is **\"+sample_sentence,\"**\")\n",
    "\n",
    "features = getFeaturesForOneSentence(sample_sentence)\n",
    "# Checking the features of a sample sentence\n",
    "for index,word in enumerate(sample_sentence.split()):\n",
    "  print(\"\\033[1m\",\"Word = \",word,\"\\033[0m\" )\n",
    "  print(features[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0YAUN7zBxxU"
   },
   "source": [
    "## <font color=\"blue\"> Defining input and target variables:\n",
    "\n",
    "Correctly computing X and Y sequence matrices for training and test data.\n",
    "Check that both sentences and labels are processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCfrmdsfHmVu"
   },
   "source": [
    "**Extracting the features values for each sentence as an input variable for the CRF model in the test and the train dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "5oNhyvOq4keV"
   },
   "outputs": [],
   "source": [
    "# Creating features for all the sentences in train and test\n",
    "X_train = [getFeaturesForOneSentence(sentence) for sentence in train_sentences]\n",
    "X_test = [getFeaturesForOneSentence(sentence) for sentence in test_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-QwXJqOIAYC"
   },
   "source": [
    "**Define the labels as the target variable for test and the train dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PuwaDJTtH9q3"
   },
   "outputs": [],
   "source": [
    "# Creating labels in list for one sentence\n",
    "Y_train = [getLabelsInListForOneSentence(labels) for labels in train_labels]\n",
    "Y_test = [getLabelsInListForOneSentence(labels) for labels in test_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAhF5I5wImYo"
   },
   "source": [
    "## <font color=\"blue\"> Build the CRF Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "lCHnQxJUKQZL"
   },
   "outputs": [],
   "source": [
    "#!pip install scikit-learn==0.22.2 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7QNHII5eI94p",
    "outputId": "5bb7b069-a788-4632-e51c-be4bdc3d8c26"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm=None, all_possible_states=None, all_possible_transitions=None,\n",
       "    averaging=None, c=None, c1=None, c2=None, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=300,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the model\n",
    "crf = sklearn_crfsuite.CRF(max_iterations=300)\n",
    "crf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WstGCha5K_s6"
   },
   "source": [
    "## <font color=\"blue\"> Evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5lOJW31LI6p"
   },
   "source": [
    "**Predicting the labels of each of the tokens in each sentence of the test dataset that has been preprocessed earlier.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "K99n_4aXLEQo"
   },
   "outputs": [],
   "source": [
    "# Predicting labels for the test sentences\n",
    "Y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdUQ_vw0Ld1I"
   },
   "source": [
    "**Calculating the f1 score using the actual and the predicted labels of the test dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OCTch46LatP",
    "outputId": "b76d332a-2798-4864-9f5d-2f8b1c993bcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is = 0.9112\n"
     ]
    }
   ],
   "source": [
    "# Calculating the f1 score\n",
    "f1_score = metrics.flat_f1_score(Y_test, Y_pred, average=\"weighted\")\n",
    "print(f\"F1 score is = {round(f1_score,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ir5AHRo1NH5f"
   },
   "source": [
    "## <font color=\"blue\"> Identifying the diseases and treatment using a custom NER: \n",
    "\n",
    "We now use the CRF model's prediction to prepare a record of diseases identified in the corpus and treatments used for the diseases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "YwWxbdvRPJ2y"
   },
   "outputs": [],
   "source": [
    "# Creating a dictionary\n",
    "Disease_Treatment_Dict = dict()\n",
    "\n",
    "# looping through all the sentences in the test sentences\n",
    "for i in range(len(test_sentences)):\n",
    "  labels_list = Y_pred[i]\n",
    "\n",
    "  # Creating an empty string to store the diseases and treatments\n",
    "  disease = \"\"\n",
    "  treatments = \"\"\n",
    "\n",
    "  # Storing the words that belongs to D and T in disease and treatments string respectively\n",
    "  for j,label in enumerate(labels_list):\n",
    "    if label == \"D\":\n",
    "      disease += test_sentences[i].split()[j]+\" \"\n",
    "    elif label == \"T\":\n",
    "      treatments += test_sentences[i].split()[j]+\" \"\n",
    "  \n",
    "  # Cleaning the space at the end of the string\n",
    "  disease = disease.lstrip().rstrip()\n",
    "  treatments = treatments.lstrip().rstrip()\n",
    "\n",
    "  # Storing the non empty disease and treatments into the disease treatment dictionary\n",
    "  if disease != \"\" and treatments != \"\":\n",
    "    if disease not in Disease_Treatment_Dict.keys():\n",
    "      Disease_Treatment_Dict[disease] = treatments\n",
    "    elif disease in Disease_Treatment_Dict.keys():\n",
    "      treat_list = Disease_Treatment_Dict[disease].split(\" \")\n",
    "      treat_list.append(treatments)\n",
    "      Disease_Treatment_Dict[disease] = treat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S42pBNaNJpgO",
    "outputId": "8faafaea-6844-4621-fcbb-24a69eadd757"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B16 melanoma': 'adenosine triphosphate and treatment with buthionine sulfoximine',\n",
       " \"Barrett 's esophagus\": 'Acid suppression therapy',\n",
       " 'CBD stones': 'one-time surgical exploration',\n",
       " \"Eisenmenger 's syndrome\": 'laparoscopic cholecystectomy',\n",
       " \"Parkinson 's disease\": 'Microelectrode-guided posteroventral pallidotomy',\n",
       " \"abdominal tuberculosis Crohn 's disease\": 'steroids',\n",
       " 'acoustic neuroma': 'Stereotactic radiosurgery',\n",
       " 'acute cerebral ischemia': 'Antiplatelet therapy',\n",
       " 'acute myocardial infarction': 'Thrombolytic therapy',\n",
       " 'acute nasopharyngitis ( ANP )': 'antibiotic treatment',\n",
       " 'acute occlusion of the middle cerebral artery': 'thrombolytic therapy',\n",
       " 'advanced esophageal cancer': 'adjuvant chemoradiotherapy with CDDP',\n",
       " 'advanced non -- small-cell lung cancer': 'paclitaxel plus carboplatin ( pc ) vinorelbine plus cisplatin',\n",
       " 'advanced nsclc': 'assessing combination chemotherapy of cisplatin , ifosfamide and irinotecan with rhg-csf support',\n",
       " 'advanced rectal cancer': 'Nerve-sparing surgery',\n",
       " 'advanced renal cell carcinoma': 'various interferon alpha preparations interferon alfa-N1 , interferon alfa-2a , and interferon alfa-2b',\n",
       " 'advanced stage ( TNM IIB-IVB ) mycosis fungoides': 'a combination chemotherapy program consisting of bleomycin and methotrexate weekly , doxorubicin every',\n",
       " 'asthma': 'Fluticasone propionate several inhaled corticosteroids',\n",
       " 'autoimmune hemolytic anemia': 'heparin',\n",
       " 'biliary dyskinesia': 'Cholecystectomy',\n",
       " 'breast cancer': ['Hormone',\n",
       "  'replacement',\n",
       "  'therapy',\n",
       "  'undergone subcutaneous mastectomy'],\n",
       " 'bronchiectasis': ['antibiotics',\n",
       "  'and',\n",
       "  'surgery',\n",
       "  'Current surgical therapy'],\n",
       " 'cancer': ['oral',\n",
       "  'drugs',\n",
       "  'chemotherapy',\n",
       "  'Matrix metalloproteinase inhibitors'],\n",
       " 'cerebral palsy': 'Hyperbaric oxygen therapy',\n",
       " 'chronic hepatitis C': 'Combination therapy with interferon-alpha ( IFN alpha ) plus Ribavirin',\n",
       " 'colorectal cancer': 'Elective surgery',\n",
       " 'colorectal metastases': 'therapeutic vats metastasectomy',\n",
       " 'coronary-artery disease': 'Antichlamydial antibiotics',\n",
       " 'disseminated malignant melanoma': 'leukocyte A recombinant interferon ( rIFN-alpha A',\n",
       " 'duodenogastric reflux': 'cholecystectomy',\n",
       " \"early Parkinson 's disease\": 'Ropinirole monotherapy',\n",
       " 'epithelial ovarian cancer': 'High-dose chemotherapy',\n",
       " 'esophageal achalasia': 'botulinum toxin injection , pneumatic dilation , and laparoscopic myotomy',\n",
       " 'essential hypertension': 'moxonidine',\n",
       " 'extensive disease': 'platinum dose ( cisplatin plus carboplatin ) in combination chemotherapy combination therapy with carboplatin',\n",
       " 'female stress urinary incontinence': 'surgical treatment',\n",
       " 'foot infection': 'G-CSF treatment',\n",
       " 'gastrointestinal tumours': 'Elective surgery',\n",
       " 'head and neck cancer xerostomia': 'irradiation therapy intravenous amifostine',\n",
       " 'hepatic metastases from colorectal cancer': 'Hepatic arterial infusion of chemotherapy after resection',\n",
       " 'hepatitis B': 'vaccine containing MF59 adjuvant',\n",
       " 'hepatitis C viremia': 'combination therapy',\n",
       " 'hereditary retinoblastoma': 'radiotherapy',\n",
       " 'infection': 'a combination of omeprazole , amoxicillin , and clarithromycin',\n",
       " 'inflammation': 'video-assisted thoracoscopic surgery',\n",
       " 'inflammatory skin diseases': 'topical corticosteroids',\n",
       " 'inoperable advanced malignancies such as colorectal cancer': 'combination with leucovorin or cisplatin',\n",
       " 'intraluminal early-stage cancer': 'photodynamic therapy , nd-yag laser and electrocautery',\n",
       " 'leukemia': 'Trisomy',\n",
       " 'limited stage small cell lung cancer': 'vip combination chemotherapy and early concurrent thoracic irradiation',\n",
       " 'locally advanced non-small-cell lung cancer ( la-nsclc )': 'chemotherapy and radiotherapy )',\n",
       " \"low-grade non-Hodgkin 's lymphoma\": 'interferon alpha',\n",
       " 'lung carcinoma': 'videothoracoscopic lobectomy or partial resection open thoracotomy',\n",
       " 'major pulmonary embolism': 'Thrombolytic treatment',\n",
       " 'malignant melanoma': 'single agent therapy interferon alfa-2a',\n",
       " 'malignant pleural effusions from nsclc': 'systemic chemotherapy',\n",
       " 'malignant pleural mesothelioma': 'thoracotomy , radiotherapy , and chemotherapy',\n",
       " 'melanoma ovarian carcinoma brain metastasis': 'surgical resection',\n",
       " 'metastatic colorectal cancer': 'intravenous oxaliplatin',\n",
       " 'mitomycin-resistant bladder cancer': 'photodynamic therapy in combination with mitomycin C',\n",
       " 'multiple sclerosis': ['Interferon',\n",
       "  'beta',\n",
       "  'treatment',\n",
       "  'Intravenous immunoglobulin treatment'],\n",
       " 'myocardial angiogenesis': 'Gene therapy',\n",
       " \"non-hodgkin 's lymphoma , breast cancer , mesothelioma and non-small cell lung cancer\": 'oxaliplatin',\n",
       " 'non-obstructive azoospermia': 'testicular fine needle aspiration ( TEFNA ) open biopsy and testicular sperm extraction ( TESE )',\n",
       " 'non-seminomatous germ-cell tumors': 'chemotherapy',\n",
       " 'non-small cell lung cancer advanced hormone refractory prostate cancer': 'paclitaxel and carboplatin',\n",
       " 'non-small-cell-lung-cancer ( nsclc )': 'cisplatin and radiotherapy',\n",
       " 'nonimmune hydrops fetalis': 'Trisomy',\n",
       " 'nsclc': ['platinum-based', 'chemotherapy', 'chemotherapy'],\n",
       " 'nsclc nsclc sclc': 'got surgical treatment radiotherapy',\n",
       " 'other cancers platinum-pretreated ovarian cancer': 'oxaliplatin',\n",
       " 'peritoneal tumors': 'Subcutaneous injection of irradiated LLC-IL2 did not',\n",
       " 'persistent asthma': 'Contemporary asthma management guidelines list inhaled corticosteroids',\n",
       " 'phaeochromocytoma': 'Adrenalectomy',\n",
       " 'postvitrectomy diabetic vitreous hemorrhage': 'Peripheral retinal cryotherapy',\n",
       " 'preeclampsia ( proteinuric hypertension': 'intrauterine insemination with donor sperm versus intrauterine insemination',\n",
       " 'primary cancer': ['adjuvant', 'radiation', 'therapy', 'Immunotherapy'],\n",
       " 'primary lung cancer adenocarcinoma squamous cell carcinoma': 'resection',\n",
       " 'primary pulmonary hypertension ( PPH )': 'fenfluramines',\n",
       " 'primary sclerosing cholangitis ( PSC )': 'oral budesonide',\n",
       " 'primary uveal melanoma': 'transpupillary thermotherapy',\n",
       " 'prostate cancer': 'radical prostatectomy and iodine 125 interstitial radiotherapy',\n",
       " 'proximal hypospadias': 'Tubularized incised plate hypospadias repair',\n",
       " 'psoriasis': 'active vitamin D3 analogue , 1 alpha',\n",
       " 'pulmonary symptoms attributable': 'chemotherapy',\n",
       " 'radiation-induced myelopathy': 'heparin and enoxaparin',\n",
       " 'renal cell carcinoma': 'Interferon treatment',\n",
       " 'responsive multiple myeloma': \"`` Tandem '' high-dose chemoradiotherapy with autologous stem-cell support\",\n",
       " 'rhinovirus colds rhinovirus': 'clarithromycin',\n",
       " 'severe acquired hyperammonemia cancer': 'organ transplantation and chemotherapy',\n",
       " 'severe hypoxemia': 'glucocorticoid pulse therapy',\n",
       " 'severe secondary peritonitis': 'Surgical management',\n",
       " 'small cell lung cancer': 'prophylactic cranial irradiation prolongs',\n",
       " 'small-cell lung cancer': ['chemotherapy', 'combination chemotherapy'],\n",
       " 'soft tissue sarcomas': 'Radiotherapy',\n",
       " 'some malignant tumors such as non-small cell lung cancer': 'surgery',\n",
       " 'sore throat': 'Antibiotics',\n",
       " 'spinal adhesive arachnoiditis': 'Surgical management',\n",
       " 'spontaneous pneumothorax': 'Thoracoscopic surgery',\n",
       " 'stage 0 lung carcinoma': 'curative therapy',\n",
       " 'stage iii nsclc': 'chemotherapy administered before surgery',\n",
       " 'stress urinary incontinence': 'therapy',\n",
       " 'supraclavicular node metastases in nsclc': 'chemoradiotherapy',\n",
       " 'symptoms of a common cold': 'Macrolide antibiotics',\n",
       " 'the common cold': 'pseudoephedrine plus',\n",
       " 'tumors': 'Immunotherapy',\n",
       " 'unresectable stage iii nsclc': 'sequential chemotherapy',\n",
       " 'unstable angina or non-Q-wave myocardial infarction': 'roxithromycin',\n",
       " 'untreated small cell lung cancer ( sclc ) untreated sclc': 'chemotherapy',\n",
       " 'ventricular tachycardia': 'Guiding surgical therapy'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the dictionary\n",
    "Disease_Treatment_Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c46r8OzdfT-X"
   },
   "source": [
    "**Predicting the treatment for the disease name: 'hereditary retinoblastoma'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "0qYpBr6gTnsF",
    "outputId": "74843707-717d-45d9-c946-a89e87c7f74f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'radiotherapy'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the treatment for hereditary retinoblastoma disease\n",
    "Disease_Treatment_Dict['hereditary retinoblastoma']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "uUSoXPaYfQYY",
    "Y-LVDJxO4C48",
    "zj8JYesM_4ai",
    "I0YAUN7zBxxU",
    "bAhF5I5wImYo"
   ],
   "name": "NER-healthcare data",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
